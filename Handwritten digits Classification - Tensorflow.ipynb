{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600\n",
      "8400\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('.\\\\data\\\\digit-recognizer\\\\train.csv')\n",
    "split_ratio = 0.8\n",
    "total_size = len(data)\n",
    "train_size = int(split_ratio * total_size)\n",
    "train_data = data[:train_size]\n",
    "test_data = data[train_size:]\n",
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data['label']\n",
    "x_train = train_data.drop(['label'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batched_data():\n",
    "    current_pos = 0\n",
    "     \n",
    "    total_size = len(x_train)\n",
    "    steps_per_epoch = total_size / batch_size\n",
    "    \n",
    "    def one_hot_encode_y(y_value):\n",
    "        ohe_vector = np.zeros((10, ))\n",
    "        ohe_vector[y_value] = 1\n",
    "        return ohe_vector\n",
    "    \n",
    "    for i in np.arange(steps_per_epoch):\n",
    "        x_batched = x_train[current_pos: current_pos + batch_size].values\n",
    "        x_batched_reshaped = np.array([x.reshape((28, 28, 1)) for x  in x_batched])#list(map(lambda x: x.reshape((28, 28)), x_batched)))\n",
    "        y_batched = y_train[current_pos: current_pos + batch_size].values.tolist()\n",
    "        y_batched_encoded = np.array([one_hot_encode_y(y) for y in y_batched])#list(map(lambda x: one_hot_encode_y(x), y_batched)))\n",
    "        current_pos += batch_size\n",
    "        yield x_batched_reshaped, y_batched_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "input_image = tf.placeholder(dtype = tf.float32, shape = [None, 28, 28, 1], name = 'input_image')\n",
    "y_actual = tf.placeholder(dtype = tf.float32, shape = [None, 10], name = 'y_actual')\n",
    "\n",
    "conv1_w = tf.get_variable('conv1_w', shape = [3, 3, 1, 32], initializer = tf.contrib.layers.xavier_initializer())\n",
    "conv1_b = tf.get_variable('conv1_b', initializer = tf.constant(0.1, shape = [32]))\n",
    "\n",
    "conv1 = tf.nn.conv2d(input_image, conv1_w, strides = [1, 1, 1, 1], padding = 'VALID') + conv1_b\n",
    "out1 = tf.nn.relu(conv1, name = 'relu1')\n",
    "\n",
    "maxpool1 = tf.nn.max_pool(out1, ksize = [1, 2, 2, 1], strides= [1, 1, 1, 1], padding = 'VALID', name = 'maxpool1')\n",
    "\n",
    "conv2_w = tf.get_variable('conv2_w', shape = [3, 3, 32, 64], initializer = tf.contrib.layers.xavier_initializer())\n",
    "conv2_b = tf.get_variable('conv2_b', initializer = tf.constant(0.1, shape = [64]))\n",
    "\n",
    "conv2 = tf.nn.conv2d(maxpool1, conv2_w, strides = [1, 1, 1, 1], padding = 'VALID') + conv2_b\n",
    "out2 = tf.nn.relu(conv2, name = 'relu2')\n",
    "\n",
    "maxpool2 = tf.nn.max_pool(out2, ksize = [1, 2, 2, 1], strides = [1, 1, 1, 1], padding = 'VALID', name = 'maxpool2')\n",
    "\n",
    "norm_out2 = tf.contrib.layers.batch_norm(maxpool2)\n",
    "\n",
    "conv3_w = tf.get_variable('conv3_w', shape = [3, 3, 64, 128], initializer = tf.contrib.layers.xavier_initializer())\n",
    "conv3_b = tf.get_variable('conv3_b', initializer = tf.constant(0.1, shape = [128]))\n",
    "\n",
    "conv3 = tf.nn.conv2d(norm_out2, conv3_w, strides = [1, 1, 1, 1], padding = 'VALID') + conv3_b\n",
    "out3 = tf.nn.relu(conv3, name = 'relu3')\n",
    "\n",
    "out3_flattened = tf.reshape(out3, [-1, 51200])\n",
    "\n",
    "fc4_w = tf.get_variable('fc4_w', shape = [51200, 10], initializer = tf.contrib.layers.xavier_initializer())\n",
    "fc4_b = tf.get_variable('fc4_b', initializer = tf.constant(0.1, shape = [10]))\n",
    "\n",
    "y_pred = tf.nn.softmax(tf.matmul(out3_flattened, fc4_w) + fc4_b, name = 'y_pred')\n",
    "\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(y_actual * tf.log(y_pred), [1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(1e-4)\n",
    "train_step = optimizer.minimize(loss)\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iteration for epoch: 0, step_count: 0\n",
      "Running iteration for epoch: 0, step_count: 10\n",
      "Running iteration for epoch: 0, step_count: 20\n",
      "Running iteration for epoch: 0, step_count: 30\n",
      "Running iteration for epoch: 0, step_count: 40\n",
      "Running iteration for epoch: 0, step_count: 50\n",
      "Running iteration for epoch: 0, step_count: 60\n",
      "Running iteration for epoch: 0, step_count: 70\n",
      "Running iteration for epoch: 0, step_count: 80\n",
      "Running iteration for epoch: 0, step_count: 90\n",
      "Running iteration for epoch: 0, step_count: 100\n",
      "Running iteration for epoch: 0, step_count: 110\n",
      "Running iteration for epoch: 0, step_count: 120\n",
      "Running iteration for epoch: 0, step_count: 130\n",
      "Running iteration for epoch: 0, step_count: 140\n",
      "Running iteration for epoch: 0, step_count: 150\n",
      "Running iteration for epoch: 0, step_count: 160\n",
      "Running iteration for epoch: 0, step_count: 170\n",
      "Running iteration for epoch: 0, step_count: 180\n",
      "Running iteration for epoch: 0, step_count: 190\n",
      "Running iteration for epoch: 0, step_count: 200\n",
      "Running iteration for epoch: 0, step_count: 210\n",
      "Running iteration for epoch: 0, step_count: 220\n",
      "Running iteration for epoch: 0, step_count: 230\n",
      "Running iteration for epoch: 0, step_count: 240\n",
      "Running iteration for epoch: 0, step_count: 250\n",
      "Running iteration for epoch: 0, step_count: 260\n",
      "Running iteration for epoch: 0, step_count: 270\n",
      "Running iteration for epoch: 0, step_count: 280\n",
      "Running iteration for epoch: 0, step_count: 290\n",
      "Running iteration for epoch: 0, step_count: 300\n",
      "Running iteration for epoch: 0, step_count: 310\n",
      "Running iteration for epoch: 0, step_count: 320\n",
      "Running iteration for epoch: 0, step_count: 330\n",
      "Running iteration for epoch: 1, step_count: 0\n",
      "Running iteration for epoch: 1, step_count: 10\n",
      "Running iteration for epoch: 1, step_count: 20\n",
      "Running iteration for epoch: 1, step_count: 30\n",
      "Running iteration for epoch: 1, step_count: 40\n",
      "Running iteration for epoch: 1, step_count: 50\n",
      "Running iteration for epoch: 1, step_count: 60\n",
      "Running iteration for epoch: 1, step_count: 70\n",
      "Running iteration for epoch: 1, step_count: 80\n",
      "Running iteration for epoch: 1, step_count: 90\n",
      "Running iteration for epoch: 1, step_count: 100\n",
      "Running iteration for epoch: 1, step_count: 110\n",
      "Running iteration for epoch: 1, step_count: 120\n",
      "Running iteration for epoch: 1, step_count: 130\n",
      "Running iteration for epoch: 1, step_count: 140\n",
      "Running iteration for epoch: 1, step_count: 150\n",
      "Running iteration for epoch: 1, step_count: 160\n",
      "Running iteration for epoch: 1, step_count: 170\n",
      "Running iteration for epoch: 1, step_count: 180\n",
      "Running iteration for epoch: 1, step_count: 190\n",
      "Running iteration for epoch: 1, step_count: 200\n",
      "Running iteration for epoch: 1, step_count: 210\n",
      "Running iteration for epoch: 1, step_count: 220\n",
      "Running iteration for epoch: 1, step_count: 230\n",
      "Running iteration for epoch: 1, step_count: 240\n",
      "Running iteration for epoch: 1, step_count: 250\n",
      "Running iteration for epoch: 1, step_count: 260\n",
      "Running iteration for epoch: 1, step_count: 270\n",
      "Running iteration for epoch: 1, step_count: 280\n",
      "Running iteration for epoch: 1, step_count: 290\n",
      "Running iteration for epoch: 1, step_count: 300\n",
      "Running iteration for epoch: 1, step_count: 310\n",
      "Running iteration for epoch: 1, step_count: 320\n",
      "Running iteration for epoch: 1, step_count: 330\n",
      "Running iteration for epoch: 2, step_count: 0\n",
      "Running iteration for epoch: 2, step_count: 10\n",
      "Running iteration for epoch: 2, step_count: 20\n",
      "Running iteration for epoch: 2, step_count: 30\n",
      "Running iteration for epoch: 2, step_count: 40\n",
      "Running iteration for epoch: 2, step_count: 50\n",
      "Running iteration for epoch: 2, step_count: 60\n",
      "Running iteration for epoch: 2, step_count: 70\n",
      "Running iteration for epoch: 2, step_count: 80\n",
      "Running iteration for epoch: 2, step_count: 90\n",
      "Running iteration for epoch: 2, step_count: 100\n",
      "Running iteration for epoch: 2, step_count: 110\n",
      "Running iteration for epoch: 2, step_count: 120\n",
      "Running iteration for epoch: 2, step_count: 130\n",
      "Running iteration for epoch: 2, step_count: 140\n",
      "Running iteration for epoch: 2, step_count: 150\n",
      "Running iteration for epoch: 2, step_count: 160\n",
      "Running iteration for epoch: 2, step_count: 170\n",
      "Running iteration for epoch: 2, step_count: 180\n",
      "Running iteration for epoch: 2, step_count: 190\n",
      "Running iteration for epoch: 2, step_count: 200\n",
      "Running iteration for epoch: 2, step_count: 210\n",
      "Running iteration for epoch: 2, step_count: 220\n",
      "Running iteration for epoch: 2, step_count: 230\n",
      "Running iteration for epoch: 2, step_count: 240\n",
      "Running iteration for epoch: 2, step_count: 250\n",
      "Running iteration for epoch: 2, step_count: 260\n",
      "Running iteration for epoch: 2, step_count: 270\n",
      "Running iteration for epoch: 2, step_count: 280\n",
      "Running iteration for epoch: 2, step_count: 290\n",
      "Running iteration for epoch: 2, step_count: 300\n",
      "Running iteration for epoch: 2, step_count: 310\n",
      "Running iteration for epoch: 2, step_count: 320\n",
      "Running iteration for epoch: 2, step_count: 330\n"
     ]
    }
   ],
   "source": [
    "for epoch in np.arange(epochs):\n",
    "    step_count = 0\n",
    "    for x_batched, y_batched in get_batched_data():\n",
    "        sess.run(train_step, feed_dict = {input_image: x_batched, y_actual: y_batched})\n",
    "        \n",
    "        if step_count % 10 == 0:\n",
    "            print('Running iteration for epoch: {}, step_count: {}'.format(epoch, step_count))\n",
    "            \n",
    "        step_count += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_data['label']\n",
    "x_test = test_data.drop(['label'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data():\n",
    "    \n",
    "    x_batched = x_test.values\n",
    "    x_batched_reshaped = np.array([x.reshape((28, 28, 1)) for x  in x_batched])\n",
    "    y_batched = y_test.values\n",
    "    return x_batched_reshaped, y_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_mod, test_y_mod = get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for x in test_x_mod:\n",
    "    result = sess.run(y_pred, feed_dict={input_image: [x]})\n",
    "    predictions.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9992549e-01 6.7154473e-09 1.0675867e-06 7.7174184e-11 1.2788688e-10\n",
      "  2.1589262e-08 7.3368363e-05 1.0281833e-08 1.4358060e-08 2.6773835e-08]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_predictions = [x.argmax() for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 7, 7, 2, 2, 6, 5, 7, 8, 5]\n"
     ]
    }
   ],
   "source": [
    "print(test_y_predictions[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9383333333333334\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = 0\n",
    "total_count = len(test_y_mod)\n",
    "\n",
    "for i in np.arange(total_count):\n",
    "    if test_y_predictions[i] == test_y_mod[i]:\n",
    "        correct_predictions = correct_predictions + 1\n",
    "\n",
    "accuracy = correct_predictions / total_count\n",
    "print('Accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
